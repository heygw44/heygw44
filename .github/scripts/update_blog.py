import feedparser
import re
import html
from datetime import datetime


def clean_html(raw_html: str) -> str:
    """HTML/Markdown íƒœê·¸ ì œê±°í•˜ê³  í…ìŠ¤íŠ¸ë§Œ ì¶”ì¶œí•˜ëŠ” í•¨ìˆ˜"""
    if not raw_html:
        return ""

    text = html.unescape(raw_html)
    text = re.sub(r"<.*?>", "", text)
    text = re.sub(r"\s+", " ", text)
    return text.strip()


def get_thumbnail(entry) -> str:
    """RSS ì—”íŠ¸ë¦¬ì—ì„œ ì¸ë„¤ì¼ ì´ë¯¸ì§€ URLì„ ì¶”ì¶œí•˜ëŠ” í•¨ìˆ˜"""

    def _normalize_url(url: str) -> str:
        if not url:
            return url
        url = url.strip()
        if url.startswith("//"):
            url = "https:" + url
        elif url.startswith("http://"):
            url = url.replace("http://", "https://")
        return url

    # 1. media_thumbnail
    if hasattr(entry, "media_thumbnail"):
        try:
            url = entry.media_thumbnail[0].get("url")
            url = _normalize_url(url)
            if url:
                return url
        except Exception:
            pass

    # 2. enclosures
    if hasattr(entry, "enclosures") and entry.enclosures:
        for enclosure in entry.enclosures:
            if enclosure.get("type", "").startswith("image/"):
                url = _normalize_url(enclosure.get("url"))
                if url:
                    return url

    # 3. description ë‚´ ì²« ë²ˆì§¸ <img>
    if hasattr(entry, "description") and entry.description:
        img_match = re.search(r'<img[^>]+src="([^"]+)"', entry.description)
        if img_match:
            url = _normalize_url(img_match.group(1))
            if url:
                return url

    # ê¸°ë³¸ ì´ë¯¸ì§€
    return "https://via.placeholder.com/300x200?text=No+Image"


def format_date(date_str: str) -> str:
    """RSSì˜ ë‚ ì§œë¥¼ YYYY.MM.DD í˜•ì‹ìœ¼ë¡œ ë³€í™˜"""
    if not date_str:
        return ""
    try:
        date_obj = datetime.strptime(date_str, "%a, %d %b %Y %H:%M:%S %z")
        return date_obj.strftime("%Y.%m.%d")
    except Exception:
        return date_str


def create_blog_table(feed_url: str, max_posts: int = 6) -> str:
    """RSS í”¼ë“œì—ì„œ ë¸”ë¡œê·¸ ê¸€ì„ ê°€ì ¸ì™€ 3ì—´ HTML í…Œì´ë¸” ìƒì„±"""
    feed = feedparser.parse(feed_url)
    entries = feed.entries[:max_posts]

    if not entries:
        return "<p>ìµœê·¼ ê¸€ì´ ì—†ìŠµë‹ˆë‹¤.</p>"

    table = "<table>\n"

    for i in range(0, len(entries), 3):
        row_entries = entries[i: i + 3]
        while len(row_entries) < 3:
            row_entries.append(None)

        table += "  <tr>\n"

        for entry in row_entries:
            if entry is None:
                table += "    <td></td>\n"
                continue

            thumbnail = get_thumbnail(entry)
            title = clean_html(entry.title)
            link = entry.link
            pub_date = format_date(entry.get("published", ""))

            safe_title = re.sub(r"[\[\]\(\)`]", "", title)

            # description ì œê±° â€” ì œëª© + ì´ë¯¸ì§€ + ë‚ ì§œë§Œ í‘œì‹œ
            cell = (
                f'<a href="{link}">'
                f'<img src="{thumbnail}" alt="{safe_title}" width="300" height="200" />'
                f"</a><br/>"
                f'<strong><a href="{link}">{title}</a></strong><br/>'
                f"{pub_date}"
            )

            table += f"    <td>{cell}</td>\n"

        table += "  </tr>\n"

    table += "</table>\n"
    return table


def update_readme(readme_path: str, table_content: str) -> None:
    """README.md íŒŒì¼ì˜ ë§ˆì»¤ ì‚¬ì´ ë‚´ìš©ì„ ìƒˆë¡œìš´ í…Œì´ë¸”ë¡œ ì—…ë°ì´íŠ¸"""
    with open(readme_path, "r", encoding="utf-8") as f:
        content = f.read()

    start_marker = "<!-- BLOG-POST-LIST:START -->"
    end_marker = "<!-- BLOG-POST-LIST:END -->"

    start_idx = content.find(start_marker)
    end_idx = content.find(end_marker)

    if start_idx != -1 and end_idx != -1:
        new_content = (
            content[: start_idx + len(start_marker)]
            + "\n"
            + table_content
            + "\n"
            + content[end_idx:]
        )
        with open(readme_path, "w", encoding="utf-8") as f:
            f.write(new_content)
        print("âœ… README.md updated successfully!")
    else:
        print("âŒ Could not find markers in README.md")


if __name__ == "__main__":
    RSS_FEED_URL = "https://cayman031.tistory.com/rss"
    README_PATH = "README.md"

    print("ğŸ“¡ Fetching blog posts from RSS feed...")
    table = create_blog_table(RSS_FEED_URL, max_posts=6)

    print("ğŸ“ Updating README.md...")
    update_readme(README_PATH, table)
