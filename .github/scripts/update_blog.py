import feedparser
import re
import html
from datetime import datetime


def clean_html(raw_html: str) -> str:
    """HTML/Markdown íƒœê·¸ ì œê±°í•˜ê³  í…ìŠ¤íŠ¸ë§Œ ì¶”ì¶œí•˜ëŠ” í•¨ìˆ˜"""
    if not raw_html:
        return ""
    text = html.unescape(raw_html)
    text = re.sub(r"<.*?>", "", text)
    text = re.sub(r"\[([^\]]+)\]\([^)]+\)", r"\1", text)
    text = re.sub(r"\*\*([^*]+)\*\*", r"\1", text)
    text = re.sub(r"\*([^*]+)\*", r"\1", text)
    text = text.replace("`", "")
    text = re.sub(r"\s+", " ", text)
    return text.strip()


def get_thumbnail(entry) -> str:
    """RSS ì—”íŠ¸ë¦¬ì—ì„œ ì¸ë„¤ì¼ ì´ë¯¸ì§€ URLì„ ì¶”ì¶œ"""
    def _normalize_url(url: str) -> str:
        if not url: return url
        url = url.strip()
        if url.startswith("//"): url = "https:" + url
        elif url.startswith("http://"): url = url.replace("http://", "https://")
        return url

    if hasattr(entry, "media_thumbnail"):
        try:
            url = entry.media_thumbnail[0].get("url")
            if url: return _normalize_url(url)
        except Exception: pass

    if hasattr(entry, "enclosures") and entry.enclosures:
        for enclosure in entry.enclosures:
            if enclosure.get("type", "").startswith("image/"):
                url = enclosure.get("url")
                if url: return _normalize_url(url)

    if hasattr(entry, "description") and entry.description:
        img_match = re.search(r'<img[^>]+src="([^"]+)"', entry.description)
        if img_match: return _normalize_url(img_match.group(1))

    return "https://via.placeholder.com/300x200?text=No+Image"


def format_date(date_str: str) -> str:
    """RSSì˜ ë‚ ì§œë¥¼ YYYY.MM.DD í˜•ì‹ìœ¼ë¡œ ë³€í™˜"""
    if not date_str: return ""
    try:
        date_obj = datetime.strptime(date_str, "%a, %d %b %Y %H:%M:%S %z")
        return date_obj.strftime("%Y.%m.%d")
    except Exception: return date_str


def remove_title_from_description(title: str, description: str) -> str:
    """
    ë³¸ë¬¸(description)ì´ ì œëª©(title)ìœ¼ë¡œ ì‹œì‘í•˜ëŠ” ê²½ìš° ì¤‘ë³µì„ ì œê±°í•©ë‹ˆë‹¤.
    ëŒ€ê´„í˜¸ [], íŠ¹ìˆ˜ë¬¸ì, ê³µë°± ë“±ì„ ë¬´ì‹œí•˜ê³  ë¬¸ìì—´ì˜ ìˆœì„œë§Œ ë¹„êµí•©ë‹ˆë‹¤.
    ì˜ˆ: Title="Gradle Build", Desc="[Gradle] Build ë°©ë²•" -> Match! -> "ë°©ë²•" ë°˜í™˜
    """
    # 1. ë¹„êµë¥¼ ìœ„í•´ ì œëª©ì—ì„œ ì•ŒíŒŒë²³/í•œê¸€/ìˆ«ìë§Œ ë‚¨ê¹€
    clean_title = re.sub(r"[^a-zA-Z0-9ê°€-í£]", "", title).lower()
    
    if not clean_title:
        return description

    t_idx = 0
    d_idx = 0
    last_match_idx = -1
    
    # 2. ë³¸ë¬¸ì„ í•œ ê¸€ìì”© ìˆœíšŒí•˜ë©° ì œëª©ì˜ ë¬¸ìê°€ ìˆœì„œëŒ€ë¡œ ë‚˜ì˜¤ëŠ”ì§€ í™•ì¸
    while d_idx < len(description) and t_idx < len(clean_title):
        d_char = description[d_idx]
        
        # ë³¸ë¬¸ì˜ í˜„ì¬ ê¸€ìê°€ ë¬¸ì/ìˆ«ìë¼ë©´ ì œëª©ê³¼ ë¹„êµí•´ì•¼ í•¨
        if d_char.isalnum():
            if d_char.lower() == clean_title[t_idx]:
                t_idx += 1
                last_match_idx = d_idx
            else:
                # ë¬¸ìê°€ ë‹¤ë¥¸ ê²½ìš° ì¤‘ë³µ ì•„ë‹˜ -> ì›ë³¸ ë°˜í™˜
                return description
        else:
            # ë³¸ë¬¸ì˜ íŠ¹ìˆ˜ë¬¸ì(ê´„í˜¸, ê³µë°± ë“±)ëŠ” ê±´ë„ˆëœ€ (ë¹„êµ ì•ˆí•¨)
            pass
            
        d_idx += 1

    # 3. ì œëª©ì˜ ëª¨ë“  ë¬¸ìê°€ ë³¸ë¬¸ ì•ë¶€ë¶„ì—ì„œ ìˆœì„œëŒ€ë¡œ ë°œê²¬ë¨
    if t_idx == len(clean_title):
        # ë§ˆì§€ë§‰ìœ¼ë¡œ ì¼ì¹˜í•œ ì§€ì  ë’¤ë¶€í„° ìë¦„
        cut_desc = description[last_match_idx + 1:]
        # ì•ë¶€ë¶„ì— ë‚¨ì€ ì”ì—¬ íŠ¹ìˆ˜ë¬¸ì(-, :, ], ê³µë°± ë“±) ì œê±°
        return cut_desc.lstrip(" -:|]")
    
    return description


def create_blog_table(feed_url: str, max_posts: int = 6) -> str:
    feed = feedparser.parse(feed_url)
    entries = feed.entries[:max_posts]

    if not entries:
        return "<p>ìµœê·¼ ê¸€ì´ ì—†ìŠµë‹ˆë‹¤.</p>"

    table = "<table>\n"

    for i in range(0, len(entries), 3):
        row_entries = entries[i: i + 3]
        while len(row_entries) < 3:
            row_entries.append(None)

        table += "  <tr>\n"

        for entry in row_entries:
            if entry is None:
                table += "    <td></td>\n"
                continue

            thumbnail = get_thumbnail(entry)
            title = clean_html(entry.title)
            link = entry.link
            pub_date = format_date(entry.get("published", ""))
            
            raw_desc = entry.get("description", "")
            description = clean_html(raw_desc)

            # --- [ìˆ˜ì •ëœ ë¡œì§] ìŠ¤ë§ˆíŠ¸í•œ ì¤‘ë³µ ì œê±° ---
            description = remove_title_from_description(title, description)
            
            # í˜¹ì‹œ ì¤‘ë³µ ì œê±°ê°€ ì•ˆ ë˜ì—ˆë”ë¼ë„, ë§¨ ì•ì˜ ë‹¨ìˆœ ì¹´í…Œê³ ë¦¬ íƒœê·¸ [Category]ëŠ” ì œê±° ì‹œë„
            # (ì œëª©ê³¼ ë³¸ë¬¸ì´ ì™„ì „íˆ ë‹¬ë¼ì„œ ìœ„ í•¨ìˆ˜ê°€ ì‹¤íŒ¨í–ˆì„ ê²½ìš° ëŒ€ë¹„)
            if description.startswith("[") and "]" in description[:20]:
                 description = re.sub(r"^\[[^\]]+\]\s*", "", description)
            # ------------------------------------

            # ê¸¸ì´ ì œí•œ
            max_len = 100
            if len(description) > max_len:
                description = description[:max_len].rstrip() + "..."
            
            safe_title = re.sub(r"[\[\]\(\)`]", "", title)

            cell = (
                f'<a href="{link}">'
                f'<img src="{thumbnail}" alt="{safe_title}" width="300" height="200" />'
                f"</a><br/>"
                f'<strong><a href="{link}">{title}</a></strong><br/>'
                f"{description}<br/>"
                f"{pub_date}"
            )

            table += f"    <td>{cell}</td>\n"

        table += "  </tr>\n"

    table += "</table>\n"
    return table


def update_readme(readme_path: str, table_content: str) -> None:
    with open(readme_path, "r", encoding="utf-8") as f:
        content = f.read()

    start_marker = "<!-- BLOG-POST-LIST:START -->"
    end_marker = "<!-- BLOG-POST-LIST:END -->"

    start_idx = content.find(start_marker)
    end_idx = content.find(end_marker)

    if start_idx != -1 and end_idx != -1:
        new_content = (
            content[: start_idx + len(start_marker)]
            + "\n"
            + table_content
            + "\n"
            + content[end_idx:]
        )
        with open(readme_path, "w", encoding="utf-8") as f:
            f.write(new_content)
        print("âœ… README.md updated successfully!")
    else:
        print("âŒ Could not find markers in README.md")


if __name__ == "__main__":
    RSS_FEED_URL = "https://medium.com/feed/@heygw44"
    README_PATH = "README.md"

    print("ğŸ“¡ Fetching blog posts from RSS feed...")
    table = create_blog_table(RSS_FEED_URL, max_posts=6)

    print("ğŸ“ Updating README.md...")
    update_readme(README_PATH, table)