import feedparser
import re
from datetime import datetime


def clean_html(raw_html: str) -> str:
    """HTML íƒœê·¸ ì œê±°í•˜ê³  í…ìŠ¤íŠ¸ë§Œ ì¶”ì¶œí•˜ëŠ” í•¨ìˆ˜"""
    if not raw_html:
        return ""

    # HTML íƒœê·¸ ì œê±°
    cleanr = re.compile("<.*?>")
    cleantext = re.sub(cleanr, "", raw_html)

    # ì¤„ë°”ê¿ˆ/ì—¬ëŸ¬ ê³µë°±ì„ í•˜ë‚˜ì˜ ê³µë°±ìœ¼ë¡œ ì¹˜í™˜
    cleantext = re.sub(r"\s+", " ", cleantext)
    return cleantext.strip()


def get_thumbnail(entry) -> str:
    """RSS ì—”íŠ¸ë¦¬ì—ì„œ ì¸ë„¤ì¼ ì´ë¯¸ì§€ URLì„ ì¶”ì¶œí•˜ëŠ” í•¨ìˆ˜"""

    # ìš°ì„ ìˆœìœ„ 1: RSSì˜ media:thumbnail íƒœê·¸ í™•ì¸
    if hasattr(entry, "media_thumbnail"):
        try:
            url = entry.media_thumbnail[0]["url"]
            if url:
                return url
        except Exception:
            pass

    # ìš°ì„ ìˆœìœ„ 2: enclosure íƒœê·¸ì—ì„œ ì´ë¯¸ì§€ íƒ€ì… í™•ì¸
    if hasattr(entry, "enclosures") and entry.enclosures:
        for enclosure in entry.enclosures:
            if enclosure.get("type", "").startswith("image/"):
                url = enclosure.get("url")
                if url:
                    return url

    # ìš°ì„ ìˆœìœ„ 3: ë³¸ë¬¸(description)ì—ì„œ ì²« ë²ˆì§¸ ì´ë¯¸ì§€ ì¶”ì¶œ
    if hasattr(entry, "description") and entry.description:
        img_match = re.search(r'<img[^>]+src="([^"]+)"', entry.description)
        if img_match:
            url = img_match.group(1)
            # //ë¡œ ì‹œì‘í•˜ëŠ” ê²½ìš° í”„ë¡œí† ì½œ ë³´ì •
            if url.startswith("//"):
                url = "https:" + url
            return url

    # ëª¨ë‘ ì—†ì„ ê²½ìš° ê¸°ë³¸ ì´ë¯¸ì§€ ë°˜í™˜ (êº¾ì‡  ì—†ì´ ìˆœìˆ˜ URLë§Œ)
    return "https://github.com/user-attachments/assets/9ffcad01-a362-4ad3-b3eb-f648be5d75de"


def format_date(date_str: str) -> str:
    """RSSì˜ ë‚ ì§œë¥¼ YYYY.MM.DD í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•˜ëŠ” í•¨ìˆ˜"""
    if not date_str:
        return ""

    try:
        # RSS í‘œì¤€ ë‚ ì§œ í˜•ì‹ íŒŒì‹±
        date_obj = datetime.strptime(date_str, "%a, %d %b %Y %H:%M:%S %z")
        return date_obj.strftime("%Y.%m.%d")
    except Exception:
        # íŒŒì‹± ì‹¤íŒ¨ ì‹œ ì›ë³¸ ê·¸ëŒ€ë¡œ ë°˜í™˜
        return date_str


def create_blog_table(feed_url: str, max_posts: int = 6) -> str:
    """RSS í”¼ë“œì—ì„œ ë¸”ë¡œê·¸ ê¸€ì„ ê°€ì ¸ì™€ 3x2 í…Œì´ë¸” í˜•íƒœì˜ ë§ˆí¬ë‹¤ìš´ ìƒì„±"""

    # RSS í”¼ë“œ íŒŒì‹±
    feed = feedparser.parse(feed_url)
    entries = feed.entries[:max_posts]  # ìµœì‹  ê¸€ë§Œ ê°€ì ¸ì˜¤ê¸°

    if not entries:
        return "| | | |\n|---|---|---|\n| ìµœê·¼ ê¸€ì´ ì—†ìŠµë‹ˆë‹¤. | | |\n"

    # ë§ˆí¬ë‹¤ìš´ í…Œì´ë¸” í—¤ë” (3ì—´ ê³ ì •)
    table = "| | | |\n"
    table += "|---|---|---|\n"

    # 3ê°œì”© ë¬¶ì–´ì„œ í–‰ ìƒì„±
    for i in range(0, len(entries), 3):
        row_entries = entries[i : i + 3]
        row = "|"

        for entry in row_entries:
            # ê° ê¸€ì˜ ì •ë³´ ì¶”ì¶œ
            thumbnail = get_thumbnail(entry)                   # ì¸ë„¤ì¼ ì´ë¯¸ì§€
            title = entry.title                                # ê¸€ ì œëª©
            link = entry.link                                  # ê¸€ ë§í¬
            description = clean_html(entry.get("description", ""))[:50] + "..."
            pub_date = format_date(entry.get("published", "")) # ë°œí–‰ì¼

            # ì…€ ë‚´ìš©: ì´ë¯¸ì§€ + ì œëª© + ì„¤ëª… + ë‚ ì§œ
            cell = f"""<a href="{link}">
<img src="{thumbnail}" alt="{title}" width="300" height="200" />
</a><br/>
**[{title}]({link})**  
{description}  
{pub_date}"""

            row += f" {cell} |"

        # 3ê°œ ë¯¸ë§Œì¸ ê²½ìš° ë¹ˆ ì…€ë¡œ ì±„ìš°ê¸°
        while len(row_entries) < 3:
            row += " |"
            row_entries.append(None)

        table += row + "\n"

    return table


def update_readme(readme_path: str, table_content: str) -> None:
    """README.md íŒŒì¼ì˜ ë§ˆì»¤ ì‚¬ì´ ë‚´ìš©ì„ ìƒˆë¡œìš´ í…Œì´ë¸”ë¡œ ì—…ë°ì´íŠ¸"""

    # README.md ì½ê¸°
    with open(readme_path, "r", encoding="utf-8") as f:
        content = f.read()

    # ì—…ë°ì´íŠ¸í•  ì˜ì—­ì„ ë‚˜íƒ€ë‚´ëŠ” ë§ˆì»¤
    # â†’ README.md ì— ì´ ë‘ ì¤„ì´ ìˆì–´ì•¼ í•©ë‹ˆë‹¤.
    # <!-- BLOG-POST-LIST:START -->
    # <!-- BLOG-POST-LIST:END -->
    start_marker = "<!-- BLOG-POST-LIST:START -->"
    end_marker = "<!-- BLOG-POST-LIST:END -->"

    # ë§ˆì»¤ ìœ„ì¹˜ ì°¾ê¸°
    start_idx = content.find(start_marker)
    end_idx = content.find(end_marker)

    # ë§ˆì»¤ê°€ ìˆìœ¼ë©´ ë‚´ìš© êµì²´
    if start_idx != -1 and end_idx != -1:
        new_content = (
            content[: start_idx + len(start_marker)]
            + "\n"
            + table_content
            + "\n"
            + content[end_idx:]
        )

        # README.md íŒŒì¼ì— ì“°ê¸°
        with open(readme_path, "w", encoding="utf-8") as f:
            f.write(new_content)

        print("âœ… README.md updated successfully!")
    else:
        print("âŒ Could not find markers in README.md")
        print("README.md ì— ë‹¤ìŒ ë‘ ë§ˆì»¤ê°€ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”:")
        print(start_marker)
        print(end_marker)


if __name__ == "__main__":
    # ë³¸ì¸ì˜ Tistory RSS URL
    RSS_FEED_URL = "https://cayman031.tistory.com/rss"
    README_PATH = "README.md"

    print("ğŸ“¡ Fetching blog posts from RSS feed...")
    table = create_blog_table(RSS_FEED_URL, max_posts=6)

    print("ğŸ“ Updating README.md...")
    update_readme(README_PATH, table)
